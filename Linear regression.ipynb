{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9128f322-ccc4-4290-a945-ced0eb89999a",
   "metadata": {},
   "source": [
    "## Import Both input and response file\n",
    "Change the import and export file variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739a0a9-724e-458f-9a19-960e94d3efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inputfile = 'example_explanatory_variables.csv'\n",
    "outputfile = 'example_response_variable.csv'\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_input = pd.read_csv(inputfile)\n",
    "df_output = pd.read_csv(outputfile)\n",
    "X = df_input\n",
    "y= df_output['V1']\n",
    "#print(X)\n",
    "#encapsulated OVA subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34e487-e290-4aa4-a05c-f523844d9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(df_output['V1']))\n",
    "print(df_input.head(5))\n",
    "a = df_output['V1'].copy()\n",
    "dupes = [x for n, x in enumerate(a) if x in a[:n]]\n",
    "print(dupes)\n",
    "a = a.reset_index(drop=True)\n",
    "con0 = [i for i in range(len(a)) if a[i] == 385]\n",
    "print(con0)\n",
    "X.iloc[48] == X.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7934b-248d-4421-b7e8-27112829fa58",
   "metadata": {},
   "source": [
    "## Replace elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a29f42-2a3a-461d-aaa7-9235348355f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Test = False\n",
    "\n",
    "if(Test):\n",
    "    X['Orientation'] = X.Orientation.astype(str)\n",
    "    Ori = pd.get_dummies(X.Orientation)\n",
    "    X = X.join(Ori)\n",
    "    X.dtypes \n",
    "    X = X.drop('Orientation' ,axis = 1)\n",
    "\n",
    "    Bk = pd.get_dummies(X.Backbone)\n",
    "    X = X.join(Bk)\n",
    "    X = X.drop('Backbone', axis = 1 )\n",
    "\n",
    "    OD = pd.get_dummies(X.OligoDensity)\n",
    "    X = X.join(OD, how='right')\n",
    "    X = X.drop('OligoDensity', axis = 1)\n",
    "\n",
    "    AT = pd.get_dummies(X.Attachment)\n",
    "    X = X.join(AT)\n",
    "    X = X.drop('Attachment', axis = 1)\n",
    "\n",
    "#X.loc[(X.Lipid == '100%'), 'Lipid' ] = 1\n",
    "#X.loc[(X.Lipid == '80%'), 'Lipid' ] = 0.8\n",
    "\n",
    "    X['Size'] = X.Size.astype(str)\n",
    "    Si = pd.get_dummies(X.Size)\n",
    "    X = X.join(Si)\n",
    "    X = X.drop('Size' ,axis = 1)\n",
    "\n",
    "    X['Lipid'] = X.Lipid.astype(str)\n",
    "    Li = pd.get_dummies(X.Lipid)\n",
    "    X = X.join(Li) \n",
    "    X = X.drop('Lipid' ,axis = 1)\n",
    "\n",
    "#X['OligoConc'] = X.OligoConc.astype(str)\n",
    "#OC = pd.get_dummies(X.OligoConc)\n",
    "#X = X.join(OC) \n",
    "#X = X.drop('OligoConc' ,axis = 1)\n",
    "\n",
    "    X['PeptideDensity'] = X.PeptideDensity.astype(str)\n",
    "    PD = pd.get_dummies(X.PeptideDensity)\n",
    "    X = X.join(PD) \n",
    "    X = X.drop('PeptideDensity' ,axis = 1)\n",
    "\n",
    "\n",
    "    \n",
    "Features = ['Orientation','Backbone','OligoDensity','Attachment','Size','Lipid','PeptideDensity']#,'OligoConc'\n",
    "for name in Features:\n",
    "    X[name] = X[name].astype(str)\n",
    "    tem = pd.get_dummies(X[name])\n",
    "    X = X.join(tem, how='right')\n",
    "    X = X.drop(name, axis = 1)\n",
    "        \n",
    "#X = X[['1','10','100','1000','Chol','DOPE','PO','PS','3','5','High' ,'Low', 'VHigh','PeptideDensity','100%','80%','Size']]\n",
    "#X = X[['High' ,'Low', 'VHigh','Chol','DOPE','OligoConc','PO','PS','0.0','0.05','0.5','80%','100%','50','80','3','5']]\n",
    "X = X[['OligoConc','Chol','DOPE','PO','PS','3','5','High' ,'Low','VHigh','80%','100%','0.0','0.05','0.5','50','80']]\n",
    "#'1','10','100','1000',,'0.0','0.05','0.5','80%','100%','50','80'\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ffe312-f323-43cb-90c6-8d0aaba875c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e01be-9450-49e7-94a7-36bf6bdc829e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c30a6-5ad7-451c-9293-5dd5234b11fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pred = regr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc68733-2ff1-4633-b66d-c4ee9605077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import statistics\n",
    "import numpy as np\n",
    "plt.scatter(X['OligoConc'],y)\n",
    "plt.scatter(X['OligoConc'],Pred,c = \"red\")\n",
    "print(r2_score(y,Pred))\n",
    "print(np.shape(Pred))\n",
    "print('\\nMAE is ',mean_absolute_error(y ,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = regr.coef_\n",
    "X_import = [x for x in range(len(importance))]\n",
    "plt.bar(X_import, importance.reshape(-1,))\n",
    "plt.show()\n",
    "print(importance.reshape(-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f4f0f",
   "metadata": {},
   "source": [
    "K-fold cross-validation to get Q2 value (k-folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import math\n",
    "import numpy\n",
    "def getQ2(test_pred, test_res, rand_res): \n",
    "\n",
    "# this function calculates Q2 values\n",
    "\n",
    "  # set up squared total error and squared residual error\n",
    "    SS_tot = 0\n",
    "    SS_res = 0\n",
    "  \n",
    "    # continuous variable\n",
    "      # accumulate errors\n",
    "    SS_tot = SS_tot + sum(numpy.square(numpy.subtract(test_res,rand_res)))\n",
    "    SS_res = SS_res + sum(numpy.square(numpy.subtract(test_res,test_pred)))\n",
    "    \n",
    "  # do final Q2 calculation\n",
    "    Q2 = 1 - SS_res / SS_tot\n",
    "    #Q2 = 1 - (Sum(real-predict)/Sum(real-predict_group_mean))\n",
    "  # something went wrong and there was NA (rare)\n",
    "    if math.isnan(Q2) or pd.isna(Q2):\n",
    "        Q2 = 0\n",
    "        warn(\"Q2 in Q2.R created nan\")\n",
    "    return(Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c859b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import statistics as statss\n",
    "kf = KFold(n_splits=5) #, shuffle = True\n",
    "kf.get_n_splits(X)\n",
    "regrt = linear_model.LinearRegression()\n",
    "Q2=[]\n",
    "r2 = []\n",
    "z=0\n",
    "\n",
    "#X, X_test, y, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "for p in range(8):\n",
    "    z=z+1\n",
    "    CVX = X.iloc[:, 0:z].copy()\n",
    "    if CVX.columns[len(CVX.columns)-1] == '3' or CVX.columns[len(CVX.columns)-1] == 'PO' or CVX.columns[len(CVX.columns)-1] == 'Chol'or CVX.columns[len(CVX.columns)-1] == '100%':\n",
    "        z=z+1\n",
    "        CVX = X.iloc[:, 0:z].copy()\n",
    "    elif CVX.columns[len(CVX.columns)-1] == 'High':\n",
    "        z=z+2 \n",
    "        CVX = X.iloc[:, 0:z].copy()\n",
    "    elif CVX.columns[len(CVX.columns)-1] == '1':\n",
    "        z=z+3\n",
    "        CVX = X.iloc[:, 0:z].copy()\n",
    "    #X_test_tem = X_test.iloc[:, 0:z].copy()\n",
    "    #y_test_tem = y_test\n",
    "\n",
    "#CVX = Xt.copy()\n",
    "    CVy = y.copy()\n",
    "    Q2infold = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        Test_pred = [] #predicted values\n",
    "        Test_res = []  #original values\n",
    "        rand_res = []  #training set mean values\n",
    "        \n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        trainX , trainY = CVX.iloc[train_index] , CVy.iloc[train_index]\n",
    "        testX , testY =  CVX.iloc[test_index] , CVy.iloc[test_index]\n",
    "        #print(trainY)\n",
    "        regrt.fit(trainX, trainY)\n",
    "        Pred_test = regrt.predict(testX)#testX#X_test_tem\n",
    "        Mean_trained_y=statss.mean(trainY)\n",
    "        for x in range(len(Pred_test)):\n",
    "            rand_res.append(Mean_trained_y)\n",
    "        Test_pred.extend(Pred_test)\n",
    "        Test_res.extend(testY)#testY#y_test_tem\n",
    "        \n",
    "    #print(trainX.head(2))\n",
    "        Q2infold.append(getQ2(Test_pred,Test_res,rand_res))\n",
    "        r2.append(r2_score(testY,Pred_test))\n",
    "    Q2.append(np.mean(Q2infold))\n",
    "print(Q2infold)\n",
    "print(r2)\n",
    "plt.plot([1,2,3,4,5,6,7,8],Q2)\n",
    "print(Q2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e70fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import expit, logit\n",
    "from sklearn.preprocessing import normalize\n",
    "#clf = LogisticRegression(random_state=10)\n",
    "log_y = y.copy()\n",
    "norm_y = numpy.divide(numpy.subtract(log_y, log_y.min()) , numpy.subtract(log_y.max(), log_y.min()))\n",
    "norm_y = log_y\n",
    "#mean_y = statss.mean(log_y)\n",
    "#a = numpy.array(log_y.values.tolist())\n",
    "#log_y = numpy.where(a >= mean_y, 1, 0).tolist()\n",
    "#log_X = X[['OligoConc','Chol','DOPE','PO','PS','3','5','High' ,'Low', 'VHigh','0.0','0.05','0.5','100%','80%']]#Size\n",
    "#log_X = X[['100%','80%','3','5','High' ,'Low', 'VHigh','PeptideDensity','PO','PS','Chol','DOPE','1','10','100','1000']]\n",
    "#clf.fit(log_X, log_y)\n",
    "#log_pred = clf.predict(log_X.head(100))\n",
    "#print(expit([[1, 0.5, 1], [1, 0, 1], [1, 0, 1]]))\n",
    "def sigmoid(x, a, b1,b2,b3,b4,b5,b6,b7,b8,b9,b10,b11,b12,b13,b14,b15,b16,c):\n",
    "    #print(x)\n",
    "    y = numpy.divide(c , (1 + expit(-(b1*x[:,0]+b2*x[:,1]+b3*x[:,2]+b4*x[:,3]+b5*x[:,4]+b6*x[:,5]+b7*x[:,6]+b8*x[:,7]+b9*x[:,8]+b10*x[:,9]+b11*x[:,10]+b12*x[:,11]+b13*x[:,12]+b14*x[:,13]+b15*x[:,14]+b16*x[:,15]-a))))\n",
    "    return y\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "log_X=X.copy()\n",
    "rand_resL = []\n",
    "Test_predL = []\n",
    "Test_resL = []\n",
    "for train_index, test_index in kf.split(log_X):\n",
    "    \n",
    "    trainX , trainY = log_X.iloc[train_index] , norm_y.iloc[train_index]\n",
    "    testX , testY =  log_X.iloc[test_index] , norm_y.iloc[test_index]\n",
    "\n",
    "    Xdata = np.flip(trainX.to_numpy())\n",
    "    #print(x[:,0])\n",
    "    p0 = np.repeat(1,18)\n",
    "    fitParams, fitCovariances = curve_fit(sigmoid, Xdata, np.array(trainY), p0)\n",
    "\n",
    "\n",
    "    plt.scatter(testX['OligoConc'],testY,alpha = 0.1)\n",
    "    #print(testX)\n",
    "    testXnp = np.flip(testX.to_numpy())\n",
    "    #print(fitParams[0])\n",
    "    outsig = sigmoid(testXnp,fitParams[0],fitParams[1],fitParams[2],fitParams[3],fitParams[4],fitParams[5],fitParams[6],fitParams[7],fitParams[8],fitParams[9],fitParams[10],fitParams[11],fitParams[12],fitParams[13],fitParams[14],fitParams[15],fitParams[16],fitParams[17])\n",
    "    #print(outsig)\n",
    "    plt.scatter(testX['OligoConc'],outsig,c = \"red\")\n",
    "\n",
    "    plt.show()\n",
    "    Mean_trained_y = statss.mean(trainY.values.ravel())\n",
    "    #print(Mean_trained_y)\n",
    "    for x in range(len(outsig)):\n",
    "        rand_resL.append(Mean_trained_y)\n",
    "    Test_predL.extend(outsig.ravel())\n",
    "    Test_resL.extend(testY.values.ravel())\n",
    "print(getQ2(rand_resL,Test_predL,Test_resL))\n",
    "\n",
    "    \n",
    "#print(log_X)\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "#plot_confusion_matrix(clf, log_X, log_y, values_format = 'd' , display_labels =['Did not leave', \"left\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f0a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(True):\n",
    "    norm_y = numpy.divide(numpy.subtract(log_y, log_y.min()) , numpy.subtract(log_y.max(), log_y.min()))\n",
    "    norm_y = norm_y.reset_index(drop = True)\n",
    "    #print(norm_y.index)\n",
    "    con0 = [i for i in range(len(norm_y)) if norm_y[i] == 0]\n",
    "    con1 = [i for i in range(len(norm_y)) if norm_y[i] == 1]\n",
    "    print(con0)\n",
    "    norm_y = norm_y[norm_y > 0]\n",
    "    norm_y = norm_y[norm_y < 1]\n",
    "    nnorm_y = norm_y.reset_index(drop = True)\n",
    "    print(nnorm_y[165])\n",
    "    print([i for i in range(len(nnorm_y)) if nnorm_y[i] <0.00001])\n",
    "    print(True in np.isinf(nnorm_y.to_numpy()))\n",
    "    logis_y = -numpy.log(numpy.divide(numpy.subtract(1,nnorm_y.to_numpy()),nnorm_y.to_numpy()))\n",
    "    #print(-numpy.log(numpy.divide(numpy.subtract(1,nnorm_y.to_numpy()),nnorm_y.to_numpy())))\n",
    "    print([i for i in range(len(logis_y)) if np.isinf(logis_y[i])])\n",
    "    Q2logf = []\n",
    "    zL=0\n",
    "    regrt = linear_model.LinearRegression()\n",
    "    for p in range(8):\n",
    "        Q2Log=[]\n",
    "        zL=zL+1\n",
    "        CVXL = log_X.iloc[:, 0:zL].copy()\n",
    "        if CVXL.columns[len(CVXL.columns)-1] == '3' or CVXL.columns[len(CVXL.columns)-1] == 'PO' or CVXL.columns[len(CVXL.columns)-1] == 'Chol'or CVXL.columns[len(CVXL.columns)-1] == '100%':\n",
    "            zL=zL+1\n",
    "            CVXL = log_X.iloc[:, 0:zL].copy()\n",
    "        elif CVXL.columns[len(CVXL.columns)-1] == 'High':\n",
    "            zL=zL+2 \n",
    "            CVXL = log_X.iloc[:, 0:zL].copy()\n",
    "        elif CVXL.columns[len(CVXL.columns)-1] == '1':\n",
    "            zL=zL+3\n",
    "            CVXL = log_X.iloc[:, 0:zL].copy()\n",
    "\n",
    "        CVXL = CVXL.reset_index(drop = True)\n",
    "        CVXL.drop(con0, inplace = True)\n",
    "        CVXL.drop(con1, inplace = True)\n",
    "        #print(CVXL)\n",
    "        CVyL = pd.DataFrame(logis_y).copy()\n",
    "        \n",
    "        for train_index, test_index in kf.split(CVXL):\n",
    "            Test_predL = [] #predicted values\n",
    "            Test_resL = []  #original values\n",
    "            rand_resL = []  #training set mean values\n",
    "            trainX , trainY = CVXL.iloc[train_index] , CVyL.iloc[train_index]\n",
    "            testX , testY =  CVXL.iloc[test_index] , CVyL.iloc[test_index]\n",
    "            regrt.fit(trainX, trainY)\n",
    "            Pred_test = regrt.predict(testX)#testX\n",
    "            Mean_trained_y=statss.mean(trainY.values.ravel())\n",
    "            for x in range(len(Pred_test)):\n",
    "                rand_resL.append(Mean_trained_y)\n",
    "            Test_predL.extend(Pred_test.ravel())\n",
    "            Test_resL.extend(testY.values.ravel())\n",
    "\n",
    "    #print(Test_predL)\n",
    "            Q2Log.append(getQ2(Test_predL,Test_resL,rand_resL))\n",
    "        Q2logf.append(np.mean(Q2Log))\n",
    "    print(Q2logf)\n",
    "    plt.plot([1,2,3,4,5,6,7,8],Q2logf)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4aa4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#le = LabelEncoder()\n",
    "#y_train_XGBoost = le.fit_transform(y)\n",
    "\n",
    "xgbc = xgb.XGBRegressor(tree_method=\"hist\", enable_categorical=True)#tree_method=\"gpu_hist\"#enable_categorical=True, eval_metric = mean_absolute_error\n",
    "\n",
    "\n",
    "df_inBoost =  df_input.copy()\n",
    "df_inBoost['Orientation'] = df_inBoost['Orientation'].astype(\"category\")\n",
    "df_inBoost['Backbone'] = df_inBoost['Backbone'].astype(\"category\")\n",
    "df_inBoost['OligoDensity'] = df_inBoost['OligoDensity'].astype(\"category\")\n",
    "df_inBoost['Attachment'] = df_inBoost['Attachment'].astype(\"category\")\n",
    "df_inBoost['Lipid'] = df_inBoost['Lipid'].astype(\"category\")\n",
    "df_inBoost['Size'] = df_inBoost['Size'].astype(\"category\")\n",
    "df_inBoost['PeptideDensity'] = df_inBoost['PeptideDensity'].astype(\"category\")\n",
    "df_inBoost['OligoConc'] = df_inBoost['OligoConc'].astype(\"category\")\n",
    "\n",
    "df_inBoost, df_inBoost_test, df_outputB, df_outputB_test = train_test_split(df_inBoost, df_output, test_size=0.2)\n",
    "\n",
    "print(df_inBoost.dtypes)\n",
    "print(df_inBoost.shape)\n",
    "print(df_outputB.shape)\n",
    "xgbc.fit(df_inBoost,df_outputB)\n",
    "Pred_XGB = xgbc.predict(df_inBoost_test)\n",
    "plt.scatter(df_inBoost_test['OligoConc'],df_outputB_test)\n",
    "#print(Pred_XGB)\n",
    "plt.scatter(df_inBoost_test['OligoConc'],Pred_XGB,c = \"red\")\n",
    "plt.show()\n",
    "print('\\nMAE is ',mean_absolute_error(df_outputB_test ,Pred_XGB))\n",
    "\n",
    "print(statss.mean(Pred_XGB),np.std(Pred_XGB))\n",
    "\n",
    "print(np.shape(Pred_XGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86886cf-56aa-407b-833f-1446ab083e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ad8fb",
   "metadata": {},
   "source": [
    "Q2 function for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3416661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "Q2Boost=[]\n",
    "zB=0\n",
    "xgbt = xgb.XGBRegressor(tree_method=\"hist\",enable_categorical=True)#tree_method=\"hist\",,enable_categorical=True, \n",
    "zB=8\n",
    "    #zB=zB+1\n",
    "    #CVXB = df_inBoost.iloc[:, 0:zB].copy()\n",
    "    #if CVXB.columns[len(CVXB.columns)-1] == '3' or CVXB.columns[len(CVXB.columns)-1] == 'PO' or CVXB.columns[len(CVXB.columns)-1] == 'Chol'or CVXB.columns[len(CVXB.columns)-1] == '100%':\n",
    "        #zB=zB+1\n",
    "        #CVXB = df_inBoost.iloc[:, 0:zB].copy()\n",
    "    #elif CVXB.columns[len(CVXB.columns)-1] == 'High':\n",
    "        #zB=zB+2 \n",
    "        #CVXB = df_inBoost.iloc[:, 0:zB].copy()\n",
    "    #elif CVXB.columns[len(CVXB.columns)-1] == '1':\n",
    "        #zB=zB+3\n",
    "        #CVXB = df_inBoost.iloc[:, 0:zB].copy()\n",
    "\n",
    "    #print(CVXL.head(2))\n",
    "CVXB = df_inBoost.copy()\n",
    "CVyB = df_outputB.copy()\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle = True) #, shuffle = True\n",
    "kf.get_n_splits(CVXB)\n",
    "u=0\n",
    "Q2infold = []\n",
    "for train_index, test_index in kf.split(CVXB):\n",
    "    Test_predB = [] #predicted values\n",
    "    Test_resB = []  #original values\n",
    "    rand_resB = []  #training set mean values\n",
    "    \n",
    "    print(u)\n",
    "    u=u+1\n",
    "    trainX , trainY = CVXB.iloc[train_index] , CVyB.iloc[train_index]\n",
    "    testX , testY =  CVXB.iloc[test_index] , CVyB.iloc[test_index]\n",
    "    xgbt.fit(trainX, trainY)\n",
    "    Pred_test = xgbt.predict(df_inBoost_test)#testX\n",
    "    Mean_trained_y=statss.mean(df_outputB_test.values.ravel())#trainY\n",
    "    for x in range(len(Pred_test)):\n",
    "        rand_resB.append(Mean_trained_y)\n",
    "    Test_predB.extend(Pred_test.ravel())\n",
    "    Test_resB.extend(df_outputB_test.values.ravel())#testY\n",
    "    Q2infold.append(getQ2(Test_predB,Test_resB,rand_resB))\n",
    "    print(getQ2(Test_predB,Test_resB,rand_resB))\n",
    "Q2Boost.append(np.mean(Q2infold))\n",
    "print(Q2infold)\n",
    "#Q2Boost.append(getQ2(Test_predB,Test_resB,rand_resB))\n",
    "print(Q2Boost)\n",
    "plt.plot([0,8],[Q2Boost,Q2Boost])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ad1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get importance\n",
    "importanceXG = xgbt.feature_importances_\n",
    "#summarize\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' %(i,v))\n",
    "#plot feature importance\n",
    "plt.bar([x for x in range(len(importanceXG))], importanceXG)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fb413d-fb89-4983-ab91-1c86e1061a30",
   "metadata": {},
   "source": [
    "## Diminishing points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91217bf6-914c-4696-bce8-fc8fed089764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "xgbc = xgb.XGBRegressor(tree_method=\"hist\", enable_categorical=True)#tree_method=\"gpu_hist\"#enable_categorical=True, eval_metric = mean_absolute_error\n",
    "\n",
    "\n",
    "df_inBoost =  df_input.copy()\n",
    "df_inBoost['Orientation'] = df_inBoost['Orientation'].astype(\"category\")\n",
    "df_inBoost['Backbone'] = df_inBoost['Backbone'].astype(\"category\")\n",
    "df_inBoost['OligoDensity'] = df_inBoost['OligoDensity'].astype(\"category\")\n",
    "df_inBoost['Attachment'] = df_inBoost['Attachment'].astype(\"category\")\n",
    "df_inBoost['Lipid'] = df_inBoost['Lipid'].astype(\"category\")\n",
    "df_inBoost['Size'] = df_inBoost['Size'].astype(\"category\")\n",
    "df_inBoost['PeptideDensity'] = df_inBoost['PeptideDensity'].astype(\"category\")\n",
    "#df_inBoost['OligoConc'] = df_inBoost['OligoConc'].astype(\"category\")\n",
    "\n",
    "#336+336\n",
    "df_inBoost_org = df_inBoost.copy()\n",
    "df_output_org = df_output.copy()\n",
    "Q2infold = []\n",
    "Q2Boost = []\n",
    "#tsize = np.linspace(0,1,672)\n",
    "for tsizeidx in range(671 ,0,-1):\n",
    "    if tsizeidx ==0:\n",
    "        continue\n",
    "    df_inBoost, df_inBoost_test, df_outputB, df_outputB_test = train_test_split(df_inBoost_org, df_output_org, test_size=tsizeidx)\n",
    "    Test_predB = [] #predicted values\n",
    "    Test_resB = []  #original values\n",
    "    rand_resB = []  #training set mean values\n",
    "    xgbc.fit(df_inBoost,df_outputB)\n",
    "    Pred_XGB = xgbc.predict(df_inBoost_test)\n",
    "    Mean_trained_y=statss.mean(df_outputB.values.ravel())#trainY\n",
    "    for x in range(len(Pred_XGB)):\n",
    "        rand_resB.append(Mean_trained_y)\n",
    "    Test_predB.extend(Pred_XGB.ravel())\n",
    "    Test_resB.extend(df_outputB_test.values.ravel())#testY\n",
    "    Q2infold.append(getQ2(Test_predB,Test_resB,rand_resB))\n",
    "    #print(getQ2(Test_predB,Test_resB,rand_resB))\n",
    "\n",
    "plt.plot(np.linspace(1,671,671),Q2infold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade47b4-7088-4907-b95f-a8399bfcee1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
